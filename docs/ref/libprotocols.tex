\section{\module{protocols} ---
         Protocol Definition, Declaration, and Adaptation}
\declaremodule{}{protocols}
\moduleauthor{Phillip J. Eby}{pje@telecommunity.com}
\sectionauthor{Phillip J. Eby}{pje@telecommunity.com}
\modulesynopsis{Protocol declaration and adaptation functions as described in
    PEP XXX.}

\begin{quotation}
The typical Python programmer is an integrator, someone who is
connecting components from various vendors.  Often times the
interfaces between these components require an intermediate
adapter.  Usually the burden falls upon the programmer to
study the interface exposed by one component and required by
another, determine if they are directly compatible, or develop
an adapter.  Sometimes a vendor may even include the
appropriate adapter, but then searching for the adapter and
figuring out how to deploy the adapter takes time.

\hfill --- Martelli \& Evans, PEP 246
\end{quotation}

This package builds on the object adaptation protocol presented in \pep{246}
to make it easier for component authors, framework suppliers, and other
developers to:

\begin{itemize}

\item Specify what behavior a component requires or provides

\item Specify how to adapt the interface provided by one component to that
required by another

\item Specify how to adapt objects of a particular type or class (even
built-in types) to a particular required interface

\item Automatically adapt a supplied object to a required interface, and

\item Do all of the above, even when the components or frameworks involved
were not written to take advantage of this package, and even if the frameworks
have different mechanisms for defining interfaces.

\end{itemize}

Assuming that a particular framework either already supports this package, or
has been externally adapted to do so, then framework users will typically
use this package's declaration API to declare what interfaces their classes or
objects provide, and/or to declare adaptations between interfaces or
components.

For framework developers, this package offers an opportunity to replace
tedious and repetitive type-checking code (such as \function{isinstance()},
\function{type()}, \function{hasattr()}, or interface checks) with single
calls to \function{adapt()} instead.  In addition, if the framework has
objects that represent interfaces or protocols, the framework developer can
make them usable with this package's declaration API by adding adapters for
(or direct implementations of) the \class{IOpenProtocol} interface provided
herein.

If the developer of a framework does not do these things, it may still be
possible for a framework user or third-party developer to do them, in order to
be able to use this package's API.  The user of a framework can often call
\function{adapt()} on a component before passing it to a non-adapting
framework.  And, it's possible to externally adapt a
framework's interface objects as well.

For example, the \module{protocols.classic} module includes an adapter that
implements \class{IOpenProtocol} on behalf of Zope \class{Interface}
objects.  This allows them to be used as arguments to this package's protocol
declaration API.  This works even though Zope is completely unaware of the
\module{protocols} package.  (Of course, this does not give Zope
\class{Interface} objects all of the capabilities that \class{Protocol}
objects have, but it does make their existing functionality accessible
through the same API.)

Finally, framework and non-framework developers alike may also wish to use the
\class{Protocol} and \class{Interface} base classes from this package to
define protocols or interfaces of their own, or perhaps use some of the
adaptation mechanisms supplied here to implement ``double dispatching'' or
the ``visitor pattern''.


\begin{seealso}

\seepep{246}{Object Adaptation}{PEP 246 describes an early version of the
adaptation protocol used by this package.}

\end{seealso}



































\subsection{Protocols and Interfaces \label{protocol-concepts}}

Many languages and systems provide ways of defining \strong{interfaces} that
components provide or require.  Some mechanisms are purely for documentation,
others are used at runtime to obtain or verify an implementation.  Typically,
interfaces are formal, intended for compiler-verified static type checking.

As a dynamic language, Python more often uses a looser notion of interface,
known as a \strong{protocol}.  While protocols are often very precisely
specified, their intended audience is a human reader or developer, not a
compiler or automated verification tool.

Automated verification tools, however, usually extract a high overhead cost
from developers.  The Java language, for example, requires that all methods
of an interface be defined by a class that claims to implement the
interface, even if those methods are never used in the program being
compiled!  And yet, the more important \emph{dynamic} behavior of the
interface at runtime is not captured or verifiable by the compiler, so written
documentation for human readers is still required!

In the Python language, the primary uses for objects representing protocols
or interfaces are at runtime, rather than at compile time.  Typically, such
objects are used to ask for an implementation of the interface, or supplied
by an object to claim that it provides an implementation of that interface.

In principle, any Python object may be used as a \strong{protocol object}.
However, for a variety of practical reasons, it is best that protocol objects
be hashable and comparable.  That is, protocol objects should be usable as
dictionary keys.

This still allows for a wide variety of protocol object implementations,
however.  One might assign meaning to the number 42, for example, as
referring to some hypothetical ``hitchhiker'' protocol.  More realistically,
the Microsoft COM framework uses UUIDs (Universally Unique Identifiers) to
identify interfaces.  UUIDs can be represented as Python strings, and thus
are usable as protocol objects.





But a simple string or number is often not very useful as a protocol
object.  Aside from the issue of how to assign strings or numbers to
protocols, these passive protocol objects cannot \emph{do} anything, and by
themselves they document nothing.

There are thus two more common approaches to creating protocol objects in
Python: classes (such as abstract base classes or ``ABCs''), and \strong{
interface objects}.  Interface objects are typically also defined using Python
\code{class} statements, but use a custom metaclass to create an object
that may not be usable in the same ways as a ``real'' Python class.  Many
Python frameworks (such as Twisted, Zope, and this package) provide their own
framework-specific implementations of this ``interface object'' approach.

Since classes and most interface object implementations can be used as
dictionary keys, and because their Python source code can serve as (or
be converted to) useful documentation, both of these approaches are viable
ways to create protocol objects usable with the \module{protocols} package.

In addition, inheriting from a class or interface objects is a simple way to
define implication relationships between protocol objects.  Inheriting from a
protocol to create a new protocol means that the new protocol \strong{implies}
the old protocol.  That is, any implementation or adaptation to the new
protocol, is implied to be usable in a place where the old protocol was
required.  (We will have more to say about direct and adapted implication
relationships later on, in section \ref{proto-implication}.)

At this point, we still haven't described any mechanisms for making adapters
available, or declaring what protocols are supported by a class or object
To do that, we need to define two additional kinds of protocol objects, that
have more specialized abilities.

An \strong{adapting protocol} is a protocol object that is potentially able to
adapt components to support the protocol it represents, or at least to
recognize that a component supports (or claims to support) the protocol.  To
do this, an adapting protocol must have an \function{__adapt__} method, as
will be described in section \ref{adapt-protocol}.  (Often, this method
can be added to an existing class, or patched into an interface object
implementation.)



An \strong{open protocol} is an adapting protocol that is also capable of
accepting adapter declarations, and managing its implication relationships
with other protocols.  Open protocols can be used with this package's
protocol declaration API, as long as they implement (or can be adapted to)
the \class{IOpenProtocol} interface, as will be described in section
\ref{open-protocols}.

Notice that the concepts of protocol objects, adpating protocols, and open
protocols are themselves ``protocols''.  The \module{protocols} package supplies
three interface objects that symbolize these concepts: \class{IProtocol},
\class{IAdaptingProtocol}, and \class{IOpenProtocol}, respectively.  Just as
the English phrases represent the concepts in this text, the interface objects
represent these concepts at runtime.

Whether a protocol object is as simple as a string, or as complex as an
\class{IOpenProtocol}, it can be used to request that a component provide
(or be adaptable to) the protocol that it symbolizes.  In the next section,
we'll look at how to make such a request, and how the different kinds of
protocol objects participate (or not) in fulfilling such requests.






















\subsection{\function{adapt()} and the Adaptation Protocol
\label{adapt-protocol}}

Component adaptation is the central focus of the \module{protocols} package.
All of the package's protocol declaration API depends on component adaptation
in order to function, and the rest of the package is just there to make it
easier for developers to use component adaptation in their frameworks and
programs.

Component adaptation is performed by calling the \function{adapt()} function,
whose design is based largely on the specification presented in \pep{246}:

\begin{funcdesc}{adapt}{component, protocol,
\optional{, default \optional{, factory}}}

Return an implementation of \var{protocol} (a protocol object) for
\var{component} (any object).  The implementation returned may be
\var{component}, or a wrapper that implements the protocol on its
behalf.  If no implementation is available, return \var{default}.  If no
\var{default} is provided, call \code{\var{factory}(\var{component},
\var{protocol})} and return the result.  If no \var{factory} is supplied,
raise \exception{NotImplementedError}.

\var{default} may be supplied as a positional or keyword argument.
\var{factory}, however, must be supplied as a keyword argument in order
to be used.
\end{funcdesc}

The component adaptation process performed by \function{adapt()} proceeds
in four steps:

\begin{enumerate}

\item If the protocol is a class or type, and the component is an instance
of that class or type, the component is returned unchanged.  (This quickly
disposes of the most trivial cases).

\item If the component has a \function{__conform__} method, it is called,
passing in the protocol.  If the method returns a value other than
\constant{None}, it is returned as the result of \function{adapt()}.

\item If the protocol has an \function{__adapt__} method, it is called,
passing in the component.  If the method returns a value other than
\constant{None}, it is returned as the result of \function{adapt()}.

\item Perform default processing as described above, returning \var{default},
invoking \var{factory}, or raising \exception{NotImplementedError} as
appropriate.

\end{enumerate}

This four-step process is called the \strong{adaptation protocol}.  Note
that it can be useful even in the case where neither the component nor the
protocol object are aware that the adaptation protocol exists, and it
gracefully degrades to a kind of \function{isinstance()} check in that
case.  However, if either the component or the protocol object has been
constructed (or altered) so that it has the appropriate \function{__conform__}
or \function{__adapt__} method, then much more meaningful results can be
achieved.

Throughout the rest of this document, we will say that a component
\strong{supports} a protocol, if calling \code{adapt(component,protocol)} does
not raise an error.  That is, a component supports a protocol if its
\function{__conform__} method or the protocol's \function{__adapt__} method
return a non-\constant{None} value.

This is different from saying that an object \strong{provides} a protocol.  An
object provides a protocol if \code{adapt(ob,protocol) is ob}.  Thus,
if an object \emph{provides} a protocol, it \emph{supports} the protocol, but
an object can also support a protocol by having an adapter that provides the
protocol on its behalf.

Now that you know how \function{adapt()} works, you can actually make use of it
without any of the other tools in the \module{protocols} package.  Just define
your own \function{__conform__} and \function{__adapt__} methods, and off
you go!






In practice, however, this is like creating a new kind of Python ``number''
type.  That is, it's certainly possible, but can be rather tedious and is
perhaps best left to a specialist.  For that reason, the \module{protocols}
package supplies some useful basic protocol types, and a ``declaration API''
that lets you declare how protocols, types, and objects should be adapted to
one another.  The rest of this document deals with how to use those types and
APIs.

You don't need to know about those types and APIs to create your own kinds of
protocols or components, just as you don't need to have studied Python's
numeric types or math libraries to create a numeric type of your own.  But,
if you'd like your new types to interoperate well with existing types, and
conform to users' expectations of how such a type behaves, it would be a good
idea to be familiar with existing implementations, such as the ones described
here.


























\subsubsection{Replacing Introspection with Adaptation}

Component adaptation is intended to completely replace all non-cooperative
introspection techniques, such as \function{type()}, \function{isinstance()},
\function{hasattr()}, and even interface checks.  Such introspection
tends to limit framework flexibility by unnecessarily closing policies to
extension by end users.  It often makes code maintenance more difficult as
well, since such checks are often performed in more than one place, and
must be kept in sync whenever a new interface or type must be checked.

The common use cases for such introspection are:

\begin{itemize}

\item To manually adapt a supplied component to a needed interface

\item To select one of several possible behaviors, based on the kind of
component supplied

\item To select another component, or take some action, using information
about the interfaces supported by the supplied component

\end{itemize}

Obviously, the first case is handled quite well by \function{adapt()}, at
least in an environment where it's easy to declare adapters between types and
protocols.  The second and third cases may at first seem to demand an ability
to introspect what interfaces are supported by a component.  But, as we'll
see later, they are almost always better served by defining new protocols
that supply the required behavior or metadata, and then requesting
implementations of those protocols.

In all three use cases, replacing introspection with adaptation opens the
framework to third party extensions, without further modifications being
required -- and without the need to do extensive design or documentation
of a new hook or extension point to be added to the framework.  Indeed,
the availability of a standard mechanism for adaptation means that the
extension mechanism need only be documented once: right here in this
document.


In section \ref{introspect-elim}, we will present examples of how to
refactor all three kinds of introspection code to purely adaptation-driven
code, showing how the flexibility and readability of the code improves in the
process.  But first, we will need to cover how protocols and interfaces can
be defined, declared, and adapted, using the API provided by the
\module{protocols} package.



































\subsubsection{Differences Between \function{protocols.adapt()} and \pep{246}}

If you have read \pep{246} or are looking for an exact implementation of it,
you should know that there are a few differences between the \module{protocols}
implementation of \function{adapt()} and the \pep{246} specification.  If you
don't care about these differences, you can skip this mini-appendix and
proceed directly to section \ref{protocols-defining}, ``Defining and Subclassing
Interfaces''.

The first difference is that \exception{TypeError} is treated differently in
each implementation.  \pep{246} says that if a \function{__conform__} or
\function{__adapt__} method raises a \exception{TypeError}, it should be
treated in the same way as if the method returned \constant{None}.  This was
a workaround for the issue of accidentally calling an unbound class
method, in the case where a component or protocol supplied to
\function{adapt()} was a class.

The \module{protocols} implementation of \function{adapt()} attempts to catch
such errors also, but will reraise any exception that appears to come from
\emph{within} the execution of the \function{__conform__} or
\function{__adapt__} method.  So if these methods raise a \exception{TypeError},
it will be passed through to the caller of \function{adapt}.  Thus, if you
are writing one of these methods, you should not raise a \exception{TypeError}
to signal the lack of an adaptation.  Rather, you should return \constant{None}.

Second, \exception{NotImplementedError} is raised when no adaptation is
found, and no default is supplied, rather than the \exception{TypeError}
specified by \pep{246}.  And third, \function{protocols.adapt()} has an optional
\var{factory} argument that the \pep{246} \function{adapt()} does not.

These differences are the result of experience using the \module{protocols}
package with PEAK, and advances in the Python state-of-the-art since
\pep{246} was written (over two years ago).  We believe that they make the
adaptation protocol more robust, more predictable, and easier to use for
its most common applications.






\subsection{Defining and Subclassing Interfaces \label{protocols-defining}}

The easiest way to define an interface with the protocols package is to subclass
\class{protocols.Interface}.  \class{Interface} does not supply any data or
methods of its own, so you are free to define whatever you need.  There are two
common styles of defining interfaces, illustrated below:

\begin{verbatim%
}from protocols import Interface

# "Pure" interface style

class IReadMapping(Interface):

    """A getitem-only mapping"""

    def __getitem__(key):
        """Return value for key"""


# Abstract Base Class (ABC) style

class AbstractMapping(Interface):

    """A getitem-only mapping"""

    def __getitem__(self,key):
        """Return value for key"""
        raise NotImplementedError
\end{verbatim}

The ``pure'' style emphasizes the interface as seen by the caller, and is not
intended to be subclassed for implementation.  Notice that the \code{self}
parameter is not included in its method definitions, because \code{self} is not
supplied when calling the methods.  The ``ABC'' style, on the other hand,
emphasizes implementation, as it is intended to be subclassed
for that purpose.  Therefore, it includes method bodies, even for abstract
methods.  Each style has different uses: ``ABC'' is a popular rapid development
style, while the ``pure'' approach has some distinct documentation advantages.


\class{protocols.Interface} may be used as a base class for either style.  You
should be aware, however, that Interface objects use an explicit metaclass,
\class{protocols.InterfaceClass}.  This means that if you want to subclass an
interface for implementation using another metaclass, you may need to create a
third metaclass that combines \class{InterfaceClass} with your desired
metaclass.

Subclassing a subclass of \class{Interface} creates a new \class{Interface}
that implies the first interface.  This means that any object that supports
the second interface, is considered to implicitly support the first
interface.  For example:

\begin{verbatim%
}class IReadWriteMapping(IReadMapping):

    """Mapping with getitem and setitem only"""

    def __setitem__(key,value):
        """Store value for key, return None"""

\end{verbatim}

The \code{IReadWriteMapping} interface implies the \code{IReadMapping}
interface.  Therefore, any object that supports \code{IReadWriteMapping} is
understood to also support the \code{IReadMapping} interface.  The reverse,
however, is not true.

Inheritance is only one way to declare that one interface implies another,
however, and its uses are limited.  Let's say for example, that some package
\code{A} supplies objects that support \code{IReadWriteMapping}, while package
\code{B} needs objects that support \code{IReadMapping}.  But each package
declared its own interface, neither inheriting from the other.

As developers reading the documentation of these interfaces, it is obvious to
us that \code{IReadWriteMapping} implies \code{IReadMapping}, because we
understand what they do.  But there is no way for Python to know this, unless
we explicitly state it, like this:




\begin{verbatim%
}import protocols
from A import IReadWriteMapping
from B import IReadMapping

protocols.declareAdapter(
    protocols.NO_ADAPTER_NEEDED,
    provides = [IReadMapping],
    forProtocols = [IReadWriteMapping]
)
\end{verbatim}

In the above example, we use the \module{protocols} declaration API to say that
no adapter is needed to support the \code{B.IReadMapping} interface for
objects that already support the \code{A.IReadWriteMapping} interface.

At this point, if we supply an object that supports \code{IReadWriteMapping},
to a function that expects an \code{IReadMapping}, it should work, as long as
we either call \code{adapt(ob,IReadMapping)} first, or the code we're
calling does so.

There are still other ways to declare that one interface implies another.  For
example, if the author of our example package \code{B} knew about package {A}
and its \code{IReadWriteMapping} interface, he or she might have defined
\code{IReadMapping} this way:
















\begin{verbatim%
}import protocols
from protocols import Interface

from A import IReadWriteMapping

class IReadMapping(Interface):

    """A getitem-only mapping"""

    protocols.advise(
        protocolIsSubsetOf = [IReadWriteMapping]
    )

    def __getitem__(key):
        """Return value for key"""

\end{verbatim}

This is syntax sugar for creating the interface first, and then using
\code{protocols.declareAdapter(NO_ADAPTER_NEEDED)}.  Of course, you can only use
this approach if you are the author of the interface!  Otherwise, you must use
\function{declareAdapter()} after the fact, as in the previous example.

In later sections, we will begin looking at the \module{protocols} declaration
APIs -- like \function{declareAdapter()} and \function{advise()} -- in more
detail.  But first, we must look briefly at the interfaces that the
\module{protocols} package expects from the protocols, adapters, and other
objects supplied as parameters to the declaration API.












\subsection{Interfaces Used by the Declaration API}

Like any other API, the \module{protocols} declaration API has certain
expectations regarding its parameters.  These expectations are documented and
referenced in code using interfaces defined in the \module{protocols.interfaces}
module.  (The interfaces are also exported directly from the top level of the
\module{protocols} package.)

You will rarely use or subclass any of these interface objects, unless you are
customizing or extending the system.  Three of the interfaces exist exclusively
for documentation purposes, while the rest are used in \function{adapt()} calls
made by the API.

First, let's look at the documentation-only interfaces.  It is not necessary
for you to declare that an object supports these interfaces, and the
\module{protocols} package never tries to \function{adapt()} objects to them.

\begin{description}

\item[IAdapterFactory] \hfill \\
Up until this point, we've been talking about ``adapters'' rather loosely.  The
\class{IAdapterFactory} interface formalizes the concept.  An \strong{adapter
factory} is a callable object that takes two arguments (an object and a
protocol, in that order) and returns an object that provides the protocol on
behalf of the passed-in object.

You'll notice that this is the same signature required of the optional
\var{factory} argument to \function{adapt()}.  It is also the signature required
of objects supplied as ``adapter'' or ``factory'' arguments to the declaration
API functions.

The \module{protocols} package supplies two functions that provide
this interface: \function{NO_ADAPTER_NEEDED} and \function{DOES_NOT_SUPPORT}.
\function{NO_ADAPTER_NEEDED} is used to declare that an object provides a
protocol directly, and thus it returns the object passed into it, rather than
some kind of adapter.  \function{DOES_NOT_SUPPORT} is used to declare that an
object does not support a protocol, even with an adapter.  (Since this is the
default case, \function{DOES_NOT_SUPPORT} is rarely used, except to indicate
that a subclass does not support an interface that one of its superclasses
does.)

\item[IProtocol] \hfill \\
This interface formalizes the idea of a ``protocol object''.  As you will
recall from section \ref{protocol-concepts}, a protocol object is any object
that can be used as a Python dictionary key.  The second argument to
\function{adapt()} must be a protocol object according to this definition.


\item[IAdaptingProtocol] \hfill \\
This interface formalizes the idea of an ``adapting protocol'', specifically
that it is a protocol object (i.e., it provides \class{IProtocol}) that also
has an \function{__adapt__} method as described in section \ref{adapt-protocol}.
\class{IAdaptingProtocol} is a subclass of \class{IProtocol}, so of course
\function{adapt()} accepts such objects as protocols.

\end{description}

The other three interfaces are critical to the operation of the declaration API,
and thus must be supported by objects supplied to it.  The \module{protocols}
package supplies and registers various adapter classes that provide these
interfaces on behalf of many commonly used Python object types.  So, for each
interface, we will list ``known supporters'' of that interface, whether they
are classes supplied by \module{protocols}, or built-in types that are
automatically adapted to the interface.

We will not, however, go into details here about the methods and behavior
required by each interface.  We will leave such detailed discussions to
section \ref{customizing-adaptation}, ``Customizing and Extending the
Declaration API'', since customization and extension are all that the
details are useful for.

\begin{description}










\item[IOpenProtocol] \hfill \\
This interface formalizes the idea of an ``open protocol'', that was introduced
in section \ref{protocol-concepts}.  An \class{IOpenProtocol} is an
\class{IAdaptingProtocol} that can also accept declarations made by the
\module{protocols} declaration API.

The \module{protocols} package supplies two implementations of this interface:
\class{Protocol} and \class{InterfaceClass}.  Thus, any \class{Interface}
subclass or \class{Protocol} instance is automatically considered to provide
\class{IOpenProtocol}.  \note{\class{Interface} is an instance of
\class{InterfaceClass}, and thus provides \class{IOpenProtocol}.  But if you
create an instance of an \class{Interface}, that object does not provide
\class{IOpenProtocol}, because the interfaces provided by an object and its
class (or its instances) can be different.}

In addition to its built-in implementations, the \module{protocols} package
also supplies and declares an adapter factory that adapts Zope's
\class{Interface} objects to the \class{IOpenProtocol} interface, thus allowing
you to use Zope interfaces in calls to the declaration API.  Similar adapters
for other frameworks' interfaces may be added, if there is sufficient demand
and/or contributed code, and the frameworks' authors will not add the adapters
to their frameworks.


\item[IOpenImplementor] \hfill \\
An \class{IOpenImplementor} is a class or type that can be told (via the
declaration API) what protocols its instances provide (or support via an
\class{IAdapterFactory}).  (Note that this implies that the instances have
a \class{__conform__} method).

Support for this interface is optional, since types that don't support it
can still have their instances be adapted by \class{IOpenProtocol} objects.
The \module{protocols} package does not supply any implementations or adapters
for this interface, either.  It is intended primarily as a hook for metaclasses
to receive notification about protocol declarations for their instances (i.e.
classes), as we will discuss later.





\item[IOpenProvider] \hfill \\
Because objects' behavior usually comes from a class definition, it's not that
often that you will declare that a specific object provides or supports an
interface.  But objects like functions and modules do not have a class
definition, and classes themselves sometimes provide an interface.  (For
example, one could define an \class{IClass} interface that class objects
provide.)  So, the declaration API needs to also be able to declare what
protocols an individual object (such as a function, module, or class) supports
or provides.

That's what the \class{IOpenProvider} interface is for.  An
\class{IOpenProvider} is an object with a \class{__conform__} method, that can
be told (via the declaration API) what protocols it provides (or supports via
an \class{IAdapterFactory}).

(Notice that this is different from \class{IOpenImplementor}, which deals with
an class or type's instances.  \class{IOpenProvider} deals with the object
itself.  A single object can potentially be both an \class{IOpenProvider} and an
\class{IOpenImplementor}, if it is a class or type.)

The \module{protocols} package supplies and declares an adapter factory that
adapts Python functions, modules, and ``classic class'' instances to support
this interface.  (XXX should we also supply a mixin for new-style classes?)
Thus, it is acceptable to pass a Python function, module, or instance of a
``classic'' class to any declaration API that expects an \class{IOpenProvider}
argument.

\end{description}













\subsection{Declarating Implementations and Adapters}

There are three types of relationships that a protocol can participate in:

\begin{itemize}
\item A relationship from a class or type, to a protocol it supports or adapts
to,

\item A relationship from an instance, to a protocol it provides or adapts to,
and

\item A relationship from a protocol, to a protocol that implies or is adaptable
to it.
\end{itemize}

All of these relationships may be declared by reference to the source type,
instance or protocol, the desired destination protocol, and the adapter to be
used. (In the event that no adapter is needed, the special adapter
\function{protocols.NO_ADAPTER_NEEDED} is specified.)

To declare relationships like these, the \module{protocols} declaration API
provides three ``primitive'' declaration functions.  Each takes a \var{protocol}
argument that must be adaptable to the \class{IOpenProtocol} interface, an
adapter function (or \function{protocols.NO_ADAPTER_NEEDED}), and the source
type, instance, or protocol.  The functions are
\function{declareAdapterForType()}, \function{declareAdapterForObject()}, and
\function{declareAdapterForProtocol()}, respectively.

You will not ordinarily use these primitives, however, unless you are
customizing or extending the framework.  It is generally easier to call one
of the higher level functions in the declaration API.  These higher-level
functions may make several calls to the primitive functions on your behalf, or
supply useful defaults for certain parameters.  They are, however, based
entirely on the primitive functions, which is important for customizations and
extensions.  This will be covered more in section \ref{customizing-adaptation}.

The next higher layer of declaration APIs are the explicit declaration
functions, \function{declareImplementation}, \function{declareAdapter}, and
\function{adviseObject}.  These functions are structured to support the most
common declaration use cases.

For declaring protocol information about a type or class:

\begin{funcdesc}{declareImplementation}{typ
\optional{, instancesProvide=[ ]} \optional{, instancesDoNotProvide=[ ]}}

Declare that instances of class or type \var{typ} do or do not provide
implementations of the specified protocols.  \var{instancesProvide} and
\var{instancesDoNotProvide} must be sequences of protocol objects that
provide (or are adaptable to) the \class{IOpenProtocol} interface,
such as \class{protocols.Interface} subclasses, or Zope \class{Interface}
objects.

This function is shorthand for calling \function{declareAdapterForType()}
with \function{NO_ADAPTER_NEEDED} and \function{DOES_NOT_SUPPORT} as adapters
from the type to each of the specified protocols.  Note, therefore, that the
listed protocols must be adaptable to \class{IOpenProtocol}.  See
\function{declareAdapterForType()} in section \ref{protocols-contents} for
details.
\end{funcdesc}


For declaring protocol information about a specific instance:

\begin{funcdesc}{adviseObject}{ob
\optional{, provides=[ ]} \optional{, doesNotProvide=[ ]}}
Declare that \var{ob} provides (or does not provide) the specified protocols.
This is shorthand for calling \function{declareAdapterForType()}
with \function{NO_ADAPTER_NEEDED} and \function{DOES_NOT_SUPPORT} as adapters
from the object to each of the specified protocols.  Note, therefore, that
\var{ob} must be adaptable to \class{IOpenProvider}, and the listed protocols
must be adaptable to \class{IOpenProtocol}.  See
\function{declareAdapterForObject()} in section \ref{protocols-contents} for
details.
\end{funcdesc}







And for declaring all other kinds of protocol relationships:

\begin{funcdesc}{declareAdapter}{factory, provides,
\optional{, forTypes=[ ]} \optional{, forProtocols=[ ]}
\optional{, forObjects=[ ]}}

Declare that \var{factory} provides the protocols listed in \var{provides}
as an adapter for the classes/types listed in \var{forTypes}, for objects
providing the protocols listed in \var{forProtocols}, and for the specific
objects listed in \var{forObjects}.

This function is shorthand for calling the primitive declaration
functions for each of the protocols listed in \var{provides} and each of the
sources listed in the respective keyword arguments.
\end{funcdesc}

%Notice that because \function{declareAdapter()} can call all three primitive
%declaration functions, it is capable of doing

%The \module{protocols} package supplies
%several higher-level APIs that are easier to use,

%Specifying all three items can be tedious, however, when multiple protocols,
%types

\subsubsection{Convenience Declarations in Class, Protocol and Module Bodies}

advise

\subsection{Creating and Using Adapters}

IAdapterFactory

\subsection{Protocol Implication and Adapter Precedence
\label{proto-implication}}

subsetting, extending...




\subsection{Package Contents and Contained Modules\label{protocols-contents}}

\begin{funcdesc}{adapt}{component, protocol,
\optional{, default \optional{, factory}}}

Return an implementation of \var{protocol} (a protocol object) for
\var{component} (any object).  The implementation returned may be
\var{component}, or an adapter that implements the protocol on its
behalf.  If no implementation is available, return \var{default}.  If no
\var{default} is provided, call \code{\var{factory}(\var{component},
\var{protocol})} and return the result.  If no \var{factory} is supplied,
raise \exception{NotImplementedError}.

\var{default} may be supplied as a positional or keyword argument.
\var{factory}, however, must be supplied as a keyword argument in order
to be used.

A detailed description of this function's operations and purpose may be found in
section \ref{adapt-protocol}.
\end{funcdesc}

\begin{funcdesc}{NO_ADAPTER_NEEDED}{component, protocol}
This function simply returns \var{component}.  It is a placeholder used whenever
an object, type, or protocol directly implements or implies another protocol.
Whenever an adapter is not required, but the \module{protocols} API function
you are calling requires an adapter, you should supply this function as the
adapter.  Some protocol implementations, such as the one for Zope interfaces,
are unable to handle adapters other than \function{NO_ADAPTER_NEEDED} and
\function{DOES_NOT_SUPPORT}.
\end{funcdesc}

\begin{funcdesc}{DOES_NOT_SUPPORT}{component, protocol}
This function simply returns \constant{None}.  It is a placeholder used whenever
an object, type, or protocol does not implement or imply another protocol.
Whenever adaptation is not possible, but the \module{protocols} API function
you are calling requires an adapter, you should supply this function as the
adapter.  Some protocol implementations, such as the one for Zope interfaces,
are unable to handle adapters other than \function{NO_ADAPTER_NEEDED} and
\function{DOES_NOT_SUPPORT}.
\end{funcdesc}

\begin{classdesc*}{Protocol}
\class{Protocol} is a base class that implements the \class{IOpenProtocol}
interface, supplying internal adapter registries for adapting from other
protocols or types/classes.  Note that you do not necessarily need to use this
class (or any other \class{IOpenProtocol} implementation) in
your programs.  Any object that implements the simpler \class{IProtocol} or
\class{IAdaptingProtocol} interfaces may be used as protocols for the
\function{adapt()} function.  Compliance with the \class{IOpenProtocol}
interface is only required to use the \module{protocols} declaration API.
(That is, functions whose names begin with \code{declare} or \code{advise}.)
\end{classdesc*}


\begin{classdesc}{InterfaceClass}{name, bases, dictionary}
\class{InterfaceClass}, a subclass of \class{Protocol}, is a metaclass used to
create new interfaces (i.e., protocol objects) using class statements.  You
may set a class' \code{__metaclass__} to \class{InterfaceClass}, or simply
subclass \class{Interface}.  Normally, you will only use \class{InterfaceClass}
if you need to combine it with another metaclass, in a subclass of
\class{Interface}.
\end{classdesc}


\begin{classdesc*}{Interface}
Subclass this to create an interface.  See section \ref{protocols-defining}
for more details.
\end{classdesc*}














\begin{funcdesc}{declareAdapterForType}{protocol, adapter, typ \optional{,
depth=1}}
Declare that \var{adapter} adapts instances of class or type \var{typ}
to \var{protocol}, by adapting \var{protocol} to \class{IOpenProtocol} and
calling its \function{registerImplementation} method.  If \var{typ} is adaptable
to \class{IOpenImplementor}, its \function{declareClassImplements} method is
called as well.
\end{funcdesc}

\begin{funcdesc}{declareAdapterForObject}{protocol, adapter, ob \optional{,
depth=1}}
Declare that \var{adapter} adapts the object \var{ob} to \var{protocol}, by
adapting \var{ob} to \class{IOpenProvider} and calling its
\function{declareProvides} method.  \var{protocol} is also adapted to
\class{IOpenProtocol}, and its \function{registerObject} method is called.
\end{funcdesc}

\begin{funcdesc}{declareAdapterForProtocol}{protocol, adapter, proto \optional{,
depth=1}}
Declare that \var{adapter} adapts objects that provide protocol \var{proto}
to \var{protocol}, by adapting \var{protocol} to \class{IOpenProtocol} and
calling its \function{addImpliedProtocol} method.
\end{funcdesc}

declareImplementation

adviseObject

declareAdapter

advise

Attribute

metamethod

supermeta




\subsubsection{\module{protocols.adapters} --- ``Adapter arithmetic'' support}

minimumAdapter

composeAdapters

updateWithSimplestAdapter

\subsubsection{\module{protocols.classic} --- Adapters to support built-in types
and Zope Interfaces}

\subsubsection{\module{protocols.advice} --- Metaclasses and other ``Magic''}

addClassAdvisor, isClassAdvisor, getFrameInfo



























\subsection{Customizing and Extending the Declaration API\label{customizing-adaptation}}


\subsubsection{The \class{IOpenProtocol} Interface \label{open-protocols}}

\begin{classdesc*}{IOpenProtocol}
\class{IOpenProtocol} is an interface object representing the behavior a
protocol object must provide, to be usable with the \module{protocols}
declaration API.  (That is, functions whose names begin with \code{declare}
or \code{advise}.)

Although the \module{protocols} package supplies a default implementation of
this interface (\class{protocols.Protocol}), you may use any object that
provides this interface -- and declares that it does so -- as a protocol for
the declaration APIs.

\class{IOpenProtocol} is a subclass of \class{IAdaptingProtocol}.  A complete
description of the methods this interface requires is in section
\ref{protocols-implementing}.
\end{classdesc*}

IOpenProtocol

metaclass issues, fwd ref to metamethod and supermeta

















\subsubsection{Customizing Class/Type Declaration Management}

IOpenImplementor

\subsubsection{Customizing Single-Object Declaration Management}

IOpenProvider

\subsubsection{Using Protocol Objects}
Although most common uses for protocols can be served by using \class{Interface}
objects, there are sometimes situations that call for a dynamically created
protocol, or a new kind of protocol with added or changed behaviors.

For these situations, one may wish to use the \class{Protocol} or
\class{InterfaceClass} classes directly.

Protocol

InterfaceClass

IAdaptingProtocol

IOpenProtocol


















\subsection{Examples}
\subsubsection{Replacing introspection with Adaptation \label{introspect-elim}}







































